{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data\n",
      "/Users/macoscar/Documents/04_Projects/02_FabLab/01_SmartCitizen/01_Repositories/DataAnalysis/smartcitizen-iscape-data/data/interim/sensorData.yaml\n",
      "{'CO': 162581724, 'SLOTS': ('CO', 'NO2', 'O3'), 'O3': 204160156, 'NO2': 202160411}\n"
     ]
    }
   ],
   "source": [
    "print (rootDirectory)\n",
    "interim = join(rootDirectory, 'data','interim')\n",
    "sensordata = join(interim, 'sensorData.yaml')\n",
    "print (sensordata)\n",
    "\n",
    "with open(sensordata, 'r') as yml:\n",
    "    sensors = yaml.load(yml)\n",
    "    \n",
    "print (sensors['4815']['gas_pro_board'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     127
    ]
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "import io, pytz, os, time, datetime\n",
    "from os.path import dirname, join, abspath\n",
    "from os import getcwd, pardir\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import markdown\n",
    "from dateutil import parser\n",
    "\n",
    "from IPython.display import display, Markdown, FileLink, FileLinks, clear_output, HTML\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display, clear_output\n",
    "from plotly.widgets import GraphWidget\n",
    "    \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import csv\n",
    "\n",
    "## Get Root Directory\n",
    "rootDirectory = abspath(abspath(join(getcwd(), pardir)))\n",
    "interim = join(rootDirectory, 'data','interim')\n",
    "sensordata = join(interim, 'sensorData.yaml')\n",
    "with open(sensordata, 'r') as yml:\n",
    "    sensorsData = yaml.load(yml)\n",
    "    \n",
    "yaml1 = {}\n",
    "\n",
    "class test_object:\n",
    "    \n",
    "    def __init__(self, ID):\n",
    "        self.ID = ID\n",
    "        self.yaml = {}\n",
    "        self.yaml['test'] = dict()\n",
    "        self.yaml['test']['id'] = ID\n",
    "        self.yaml['test']['devices'] = dict()\n",
    "        self.yaml['test']['devices']['kits'] = dict()       \n",
    "    \n",
    "    def add_details(self, project = 'smartcitizen', commit = '', author = '', type_test = '', report = '', comment = ''):\n",
    "        try:\n",
    "            self.yaml['test']['project'] = project\n",
    "            self.yaml['test']['commit'] = commit\n",
    "            self.yaml['test']['author'] = author\n",
    "            self.yaml['test']['type_test'] = type_test\n",
    "            self.yaml['test']['report'] = report\n",
    "            self.yaml['test']['comment'] = markdown.markdown(comment)\n",
    "            print ('Add details OK')\n",
    "        except:\n",
    "            print ('Add device NOK')\n",
    "            pass\n",
    "\n",
    "    def add_device(self, device, device_type = 'KIT', sck_version = '2.0', pm_sensor = '', alphasense = {}, device_history = None,location = 'Europe/Madrid'):\n",
    "        try:\n",
    "            self.yaml['test']['devices']['kits'][device] = dict()\n",
    "            self.yaml['test']['devices']['kits'][device]['type'] = device_type\n",
    "            self.yaml['test']['devices']['kits'][device]['SCK'] = sck_version\n",
    "            self.yaml['test']['devices']['kits'][device]['PM'] = pm_sensor\n",
    "            self.yaml['test']['devices']['kits'][device]['location'] = location\n",
    "            #### Alphasense\n",
    "            if alphasense != {}:\n",
    "                self.yaml['test']['devices']['kits'][device]['alphasense'] = alphasense\n",
    "            elif device_history != None:\n",
    "                self.yaml['test']['devices']['kits'][device]['alphasense'] = sensorsData[device_history]['gas_pro_board']\n",
    "                \n",
    "            print ('Add device {} OK'.format(device))\n",
    "        except:\n",
    "            print ('Add device {} NOK'.format(device))\n",
    "            pass\n",
    "\n",
    "    def device_files(self, device, fileNameRaw = '', fileNameInfo = '', frequency = '1Min', type_file = 'csv_new'):\n",
    "        try:\n",
    "            self.yaml['test']['devices']['kits'][device]['fileNameRaw'] = fileNameRaw\n",
    "            self.yaml['test']['devices']['kits'][device]['fileNameInfo'] = fileNameInfo\n",
    "            fileNameProc = (self.yaml['test']['id'] + '_' + self.yaml['test']['devices']['kits'][device]['type'] + '_' + str(device) + '.csv')\n",
    "            self.yaml['test']['devices']['kits'][device]['fileNameProc'] = fileNameProc\n",
    "            self.yaml['test']['devices']['kits'][device]['frequency'] = frequency\n",
    "            self.yaml['test']['devices']['kits'][device]['type_file'] = type_file  \n",
    "            print ('Add device files {} OK'.format(device))\n",
    "        \n",
    "        except:\n",
    "            print ('Add device files {} NOK'.format(device))\n",
    "            pass\n",
    "    \n",
    "    def add_reference(self, reference, fileNameRaw = '', index = {}, channels = {}, location = ''):\n",
    "        print ('Adding reference: {}'.format(reference))\n",
    "        if 'reference' not in self.yaml['test']['devices']:\n",
    "            self.yaml['test']['devices']['reference'] = dict()\n",
    "        \n",
    "        self.yaml['test']['devices']['reference'][reference] = dict()\n",
    "        self.yaml['test']['devices']['reference'][reference]['fileNameRaw'] = fileNameRaw\n",
    "        self.yaml['test']['devices']['reference'][reference]['fileNameProc'] = self.yaml['test']['id'] + '_' + str(reference) + '_REF.csv'\n",
    "        self.yaml['test']['devices']['reference'][reference]['index'] = index\n",
    "        self.yaml['test']['devices']['reference'][reference]['channels'] = channels\n",
    "        self.yaml['test']['devices']['reference'][reference]['location'] = location\n",
    "    \n",
    "    def process_files(self, _rootDirectory, _newpath):\n",
    "        \n",
    "        def get_raw_files():\n",
    "                list_raw_files = []\n",
    "                \n",
    "                if 'kits' in self.yaml['test']['devices']:\n",
    "                    for kit in self.yaml['test']['devices']['kits']:\n",
    "                        list_raw_files.append(self.yaml['test']['devices']['kits'][kit]['fileNameRaw'])\n",
    "                        \n",
    "                if 'references' in self.yaml['test']['devices']:\n",
    "                    for reference in self.yaml['test']['devices']['reference']:\n",
    "                        list_raw_files.append(self.yaml['test']['devices']['references'][reference]['fileNameRaw'])\n",
    "                        \n",
    "                return list_raw_files    \n",
    "        \n",
    "        def copy_raw_files(_raw_src_path, _raw_dst_path, _list_raw_files):\n",
    "            \n",
    "                try: \n",
    "\n",
    "                    for item in _list_raw_files:\n",
    "                        s = join(_raw_src_path, item)\n",
    "                        d = join(_raw_dst_path, item)\n",
    "                        copyfile(s, d)\n",
    "                    \n",
    "                    return True\n",
    "                \n",
    "                except:\n",
    "\n",
    "                    return False\n",
    "                \n",
    "        def date_parser(s, a):\n",
    "            return parser.parse(s).replace(microsecond=int(a[-3:])*1000)\n",
    "    \n",
    "        # Define Paths\n",
    "        raw_src_path = join(_rootDirectory, 'data', 'raw')\n",
    "        raw_dst_path = join(_newpath, 'RAW_DATA')    \n",
    "        \n",
    "        # Create Paths\n",
    "        if not os.path.exists(raw_dst_path):\n",
    "            os.makedirs(raw_dst_path)\n",
    "        \n",
    "        list_raw_files = get_raw_files()\n",
    "        # Copy raw files and process data\n",
    "        if copy_raw_files(raw_src_path, raw_dst_path, list_raw_files):\n",
    "            # Process references\n",
    "            if 'reference' in self.yaml['test']['devices']:\n",
    "                for reference in self.yaml['test']['devices']['reference']:\n",
    "                    print ('Processing reference: {}'.format(reference))\n",
    "                    src_path = join(raw_src_path, self.yaml['test']['devices']['reference'][reference]['fileNameRaw'])\n",
    "                    dst_path = join(_newpath, self.yaml['test']['id'] + '_' + str(reference) + '_REF.csv')\n",
    "                    \n",
    "                    # Time Name\n",
    "                    timeName = self.yaml['test']['devices']['reference'][reference]['index']['name']\n",
    "                    \n",
    "                    # Load Dataframe\n",
    "                    df = pd.read_csv(src_path, verbose=False, skiprows=[1]).set_index(timeName)\n",
    "                    df.index = pd.to_datetime(df.index)\n",
    "                    df.sort_index(inplace=True)\n",
    "                    \n",
    "                    df = df.groupby(pd.Grouper(freq = self.yaml['test']['devices']['reference'][reference]['index']['frequency'])).aggregate(np.mean)\n",
    "                    \n",
    "                    # Remove Duplicates and drop unnamed columns\n",
    "                    df = df[~df.index.duplicated(keep='first')]\n",
    "                    df.drop([i for i in df.columns if 'Unnamed' in i], axis=1, inplace=True)\n",
    "                    \n",
    "                    # Export to csv in destination path\n",
    "                    df.to_csv(dst_path, sep=\",\")\n",
    "                    \n",
    "            \n",
    "            # Process kits\n",
    "            if 'kits' in self.yaml['test']['devices']:\n",
    "                for kit in self.yaml['test']['devices']['kits']:\n",
    "                    print ('Processing device: {}'.format(kit))\n",
    "                    src_path = join(raw_src_path, self.yaml['test']['devices']['kits'][kit]['fileNameRaw'])\n",
    "                    dst_path = join(_newpath, self.yaml['test']['id'] + '_' + self.yaml['test']['devices']['kits'][kit]['type'] + '_' + str(kit) + '.csv')\n",
    "                    \n",
    "                    # Read file csv\n",
    "                    if self.yaml['test']['devices']['kits'][kit]['type_file'] == 'csv_new':\n",
    "                        skiprows_pd = range(1, 4)\n",
    "                        index_name = 'TIME'\n",
    "                        df = pd.read_csv(src_path, verbose=False, skiprows=skiprows_pd, encoding = 'utf-8', sep=',')\n",
    "\n",
    "                    elif self.yaml['test']['devices']['kits'][kit]['type_file'] == 'csv_old':\n",
    "                        index_name = 'Time'\n",
    "                        df = pd.read_csv(src_path, verbose=False, encoding = 'utf-8')\n",
    "                        \n",
    "                    elif self.yaml['test']['devices']['kits'][kit]['type_file'] == 'csv_ms':\n",
    "                        index_name = 'Time'\n",
    "                        df = pd.read_csv(src_path, verbose=False, encoding = 'utf-8', parse_dates=[[0,1]], date_parser=date_parser)\n",
    "                    \n",
    "                    # Find name in case of extra weird characters\n",
    "                    for column in df.columns:\n",
    "                        if index_name in column: index_found = column\n",
    "                            \n",
    "                    df.set_index(index_found, inplace = True)\n",
    "                    df.index = pd.to_datetime(df.index).tz_localize('UTC').tz_convert(self.yaml['test']['devices']['kits'][kit]['location'])\n",
    "                    df.sort_index(inplace=True)\n",
    "                            \n",
    "                    # Remove Duplicates and drop unnamed columns\n",
    "                    df = df[~df.index.duplicated(keep='first')]\n",
    "                    df.drop([i for i in df.columns if 'Unnamed' in i], axis=1, inplace=True)\n",
    "                        \n",
    "                    df.to_csv(dst_path, sep=\",\")\n",
    "                    \n",
    "                    ## Import units and ids\n",
    "                    if self.yaml['test']['devices']['kits'][kit]['type_file'] == 'csv_new':\n",
    "                        dict_header = dict()\n",
    "                        with open(src_path, 'rb') as csvfile:\n",
    "                            readercsv = csv.reader(csvfile, delimiter = ',')\n",
    "                            line = 0\n",
    "                        \n",
    "                            header = next(readercsv)[1:]\n",
    "                            unit = next(readercsv)[1:]\n",
    "                            ids = next(readercsv)[1:]\n",
    "                        \n",
    "                            for key in header:\n",
    "                                dict_header[key] = dict()\n",
    "                                dict_header[key]['unit'] = unit[header.index(key)]\n",
    "                                dict_header[key]['id'] = ids[header.index(key)]\n",
    "                            \n",
    "                            self.yaml['test']['devices']['kits'][kit]['metadata'] = dict_header\n",
    "                    \n",
    "                    ## Load txt info\n",
    "                    if self.yaml['test']['devices']['kits'][kit]['fileNameInfo'] != '':\n",
    "                        src_path_info = join(raw_src_path, self.yaml['test']['devices']['kits'][kit]['fileNameInfo'])\n",
    "                        dict_info = dict()\n",
    "                        with open(src_path_info, 'rb') as infofile:\n",
    "                            for line in infofile:\n",
    "                                line = line.strip('\\r\\n')\n",
    "                                splitter = line.find(':')\n",
    "                                dict_info[line[:splitter]]= line[splitter+2:] # Accounting for the space\n",
    "                           \n",
    "                        self.yaml['test']['devices']['kits'][kit]['info'] = dict_info\n",
    "                \n",
    "            \n",
    "            # Create yaml with test description\n",
    "            with open(join(_newpath, 'test_description.yaml'), 'w') as yaml_file:\n",
    "                yaml.dump(self.yaml, yaml_file)\n",
    "                \n",
    "            print ('Test Creation Finished')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add details OK\n",
      "Add device 5261 OK\n",
      "Add device files 5261 OK\n",
      "Add device 5262 OK\n",
      "Add device files 5262 OK\n",
      "Add device 5565 OK\n",
      "Add device files 5565 OK\n",
      "Adding reference: CITY_COUNCIL\n",
      "Adding reference: CITY_COUNCIL_DAY\n",
      "Processing reference: CITY_COUNCIL_DAY\n",
      "Processing reference: CITY_COUNCIL\n",
      "Processing device: 5565\n",
      "Processing device: 5262\n",
      "Processing device: 5261\n",
      "Test Creation Finished\n"
     ]
    }
   ],
   "source": [
    "date = '2019-02-15'\n",
    "who = 'EXT'\n",
    "name = 'DUBLIN_URBAN_BACKGROUND_2'\n",
    "\n",
    "comment = '''\n",
    "**Comment:** \n",
    "DUBLIN URBAN BACKGROUND DATA\n",
    "'''\n",
    "\n",
    "date = pd.to_datetime(date)\n",
    "\n",
    "test_id = date.strftime('%Y-%m') + '_' + who + '_' + name\n",
    "\n",
    "# Create test object\n",
    "test = test_object(test_id)\n",
    "\n",
    "# Add General test details\n",
    "test.add_details(project = 'iscape', \n",
    "                 commit = 'various', \n",
    "                 author = 'Oscar', \n",
    "                 type_test = 'indoor', \n",
    "                 report = '', \n",
    "                 comment = comment)\n",
    "\n",
    "# Add Device (as many as needed)\n",
    "test.add_device('5261', \n",
    "                device_type = 'STATION', \n",
    "                sck_version = '2.0', \n",
    "                pm_sensor = 'none', \n",
    "                device_history = '5261',\n",
    "                location = 'Europe/Dublin')\n",
    "\n",
    "test.device_files('5261', \n",
    "                  fileNameRaw = '5261.csv', \n",
    "                  fileNameInfo = '', \n",
    "                  frequency = '1Min',\n",
    "                  type_file = 'csv_old')\n",
    "\n",
    "test.add_device('5262', \n",
    "                device_type = 'STATION', \n",
    "                sck_version = '2.0', \n",
    "                pm_sensor = 'none', \n",
    "                device_history = '5262',\n",
    "                location = 'Europe/Dublin')\n",
    "\n",
    "test.device_files('5262', \n",
    "                  fileNameRaw = '5262.csv', \n",
    "                  fileNameInfo = '', \n",
    "                  frequency = '1Min',\n",
    "                  type_file = 'csv_old')\n",
    "\n",
    "## Device 2\n",
    "\n",
    "test.add_device('5565', \n",
    "                device_type = 'STATION', \n",
    "                sck_version = '2.0', \n",
    "                pm_sensor = 'none',\n",
    "                alphasense = {'CO': 162581708,\n",
    "                              'NO2': 202160421,\n",
    "                              'O3': 204160144,\n",
    "                              'slots': ['CO', 'NO2', 'O3']\n",
    "                             },\n",
    "                location = 'Europe/Dublin')\n",
    "\n",
    "test.device_files('5565', \n",
    "                  fileNameRaw = '5565.csv', \n",
    "                  fileNameInfo = '', \n",
    "                  frequency = '1Min',\n",
    "                  type_file = 'csv_old')\n",
    "  \n",
    "# Add References (as many as needed) if none, just comment it\n",
    "test.add_reference('CITY_COUNCIL', \n",
    "                  fileNameRaw = 'CITY_COUNCIL.csv', \n",
    "                  index = {'name' : 'Time',\n",
    "                           'format' : '%Y-%m-%d %H:%M:%S',\n",
    "                           'frequency' : '15Min'}, \n",
    "                  channels = {'pollutants' : ('CO', 'SO2', 'NO2', 'NO', 'NOX'), \n",
    "                              'units' : ('ppm', 'ppb', 'ppb', 'ppb', 'ppb'),\n",
    "                              'names' : ('CO_ppm', 'SO2_ppb', 'NO2_ppb', 'NO_ppb', 'NOx_ppb')\n",
    "                             },\n",
    "                  location = 'Europe/Dublin')\n",
    "\n",
    "test.add_reference('CITY_COUNCIL_DAY', \n",
    "                  fileNameRaw = 'CITY_COUNCIL_DAY.csv', \n",
    "                  index = {'name' : 'Time',\n",
    "                           'format' : '%d/%m/%Y',\n",
    "                           'frequency' : '1D'}, \n",
    "                  channels = {'pollutants' : ['PM10'], \n",
    "                              'units' : ['ugm3'],\n",
    "                              'names' : ['PM10']\n",
    "                             },\n",
    "                  location = 'Europe/Dublin')\n",
    "\n",
    "# Create folder structure under data subdir\n",
    "newpath = join(rootDirectory, 'data', 'processed', date.strftime('%Y'), date.strftime('%m'), test_id)\n",
    "\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "# Process the stuff\n",
    "test.process_files(rootDirectory, newpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Test (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_name = '2018-10_INT_TEST_TEMP_PM_CHARGE_SD'\n",
    "test_year = test_name[0:4]\n",
    "test_month = test_name[5:7]\n",
    "newpath = join(rootDirectory, 'data', test_year, test_month, test_name)\n",
    "print newpath\n",
    "\n",
    "with open(join(newpath, 'test_description.yaml'), 'r') as yaml_file:\n",
    "    yaml1 = yaml.load(yaml_file)\n",
    "    \n",
    "display(yaml1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "178px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
