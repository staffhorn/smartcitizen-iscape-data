{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     127
    ]
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "import io, pytz, os, time, datetime\n",
    "from os.path import dirname, join, abspath\n",
    "from os import getcwd, pardir\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import markdown\n",
    "from dateutil import parser\n",
    "\n",
    "from IPython.display import display, Markdown, FileLink, FileLinks, clear_output, HTML\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display, clear_output\n",
    "from plotly.widgets import GraphWidget\n",
    "    \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import csv\n",
    "\n",
    "## Get Root Directory\n",
    "rootDirectory = abspath(abspath(join(getcwd(), pardir)))\n",
    "\n",
    "yaml1 = {}\n",
    "\n",
    "class test_object:\n",
    "    \n",
    "    def __init__(self, ID):\n",
    "        self.ID = ID\n",
    "        self.yaml = {}\n",
    "        self.yaml['test'] = dict()\n",
    "        self.yaml['test']['id'] = ID\n",
    "        self.yaml['test']['devices'] = dict()\n",
    "        self.yaml['test']['devices']['kits'] = dict()       \n",
    "    \n",
    "    def add_details(self, project = 'smartcitizen', commit = '', author = '', type_test = '', report = '', comment = ''):\n",
    "        try:\n",
    "            self.yaml['test']['project'] = project\n",
    "            self.yaml['test']['commit'] = commit\n",
    "            self.yaml['test']['author'] = author\n",
    "            self.yaml['test']['type_test'] = type_test\n",
    "            self.yaml['test']['report'] = report\n",
    "            self.yaml['test']['comment'] = markdown.markdown(comment)\n",
    "            print 'Add details OK'\n",
    "        except:\n",
    "            print 'Add device NOK'\n",
    "            pass\n",
    "\n",
    "    def add_device(self, device, device_type = 'KIT', sck_version = '2.0', pm_sensor = '', alphasense = {}, location = 'Europe/Madrid'):\n",
    "        try:\n",
    "            self.yaml['test']['devices']['kits'][device] = dict()\n",
    "            self.yaml['test']['devices']['kits'][device]['type'] = device_type\n",
    "            self.yaml['test']['devices']['kits'][device]['SCK'] = sck_version\n",
    "            self.yaml['test']['devices']['kits'][device]['PM'] = pm_sensor\n",
    "            self.yaml['test']['devices']['kits'][device]['location'] = location\n",
    "            #### Alphasense\n",
    "            if alphasense != {}:\n",
    "                self.yaml['test']['devices']['kits'][device]['alphasense'] = alphasense\n",
    "                \n",
    "            print 'Add device OK'\n",
    "        except:\n",
    "            print 'Add device NOK'\n",
    "            pass\n",
    "\n",
    "    def device_files(self, device, fileNameRaw = '', fileNameInfo = '', frequency = '1Min', type_file = 'csv_new'):\n",
    "        try:\n",
    "            self.yaml['test']['devices']['kits'][device]['fileNameRaw'] = fileNameRaw\n",
    "            self.yaml['test']['devices']['kits'][device]['fileNameInfo'] = fileNameInfo\n",
    "            fileNameProc = (self.yaml['test']['id'] + '_' + self.yaml['test']['devices']['kits'][device]['type'] + '_' + str(device) + '.csv')\n",
    "            self.yaml['test']['devices']['kits'][device]['fileNameProc'] = fileNameProc\n",
    "            self.yaml['test']['devices']['kits'][device]['frequency'] = frequency\n",
    "            self.yaml['test']['devices']['kits'][device]['type_file'] = type_file  \n",
    "            print 'Add device files OK'\n",
    "        \n",
    "        except:\n",
    "            print 'Add device files NOK'\n",
    "            pass\n",
    "    \n",
    "    def add_reference(self, reference, fileNameRaw = '', index = {}, channels = {}, location = ''):\n",
    "        if 'reference' not in self.yaml['test']['devices']:\n",
    "            self.yaml['test']['devices']['reference'] = dict()\n",
    "        \n",
    "        self.yaml['test']['devices']['references'][reference] = dict()\n",
    "        self.yaml['test']['devices']['references'][reference]['fileNameRaw'] = fileNameRaw\n",
    "        self.yaml['test']['devices']['references'][reference]['index'] = index\n",
    "        self.yaml['test']['devices']['references'][reference]['channels'] = channels\n",
    "    \n",
    "    def process_files(self, _rootDirectory, _newpath):\n",
    "        \n",
    "        def get_raw_files():\n",
    "                list_raw_files = []\n",
    "                \n",
    "                if 'kits' in self.yaml['test']['devices']:\n",
    "                    for kit in self.yaml['test']['devices']['kits']:\n",
    "                        list_raw_files.append(self.yaml['test']['devices']['kits'][kit]['fileNameRaw'])\n",
    "                        \n",
    "                if 'references' in self.yaml['test']['devices']:\n",
    "                    for reference in self.yaml['test']['devices']['references']:\n",
    "                        list_raw_files.append(self.yaml['test']['devices']['references'][reference]['fileNameRaw'])\n",
    "                        \n",
    "                return list_raw_files    \n",
    "        \n",
    "        def copy_raw_files(_raw_src_path, _raw_dst_path, _list_raw_files):\n",
    "            \n",
    "                try: \n",
    "\n",
    "                    for item in _list_raw_files:\n",
    "                        s = join(_raw_src_path, item)\n",
    "                        d = join(_raw_dst_path, item)\n",
    "                        copyfile(s, d)\n",
    "                    \n",
    "                    return True\n",
    "                \n",
    "                except:\n",
    "\n",
    "                    return False\n",
    "                \n",
    "        def date_parser(s, a):\n",
    "            return parser.parse(s).replace(microsecond=int(a[-3:])*1000)\n",
    "    \n",
    "        # Define Paths\n",
    "        raw_src_path = join(_rootDirectory, 'data', 'RAW_DATA')\n",
    "        raw_dst_path = join(_newpath, 'RAW_DATA')    \n",
    "        \n",
    "        # Create Paths\n",
    "        if not os.path.exists(raw_dst_path):\n",
    "            os.makedirs(raw_dst_path)\n",
    "        \n",
    "        list_raw_files = get_raw_files()\n",
    "        # Copy raw files and process data\n",
    "        if copy_raw_files(raw_src_path, raw_dst_path, list_raw_files):\n",
    "            # Process references\n",
    "            if 'references' in self.yaml['test']['devices']:\n",
    "                for reference in self.yaml['test']['devices']['references']:\n",
    "                    src_path = join(raw_src_path, self.yaml['test']['devices']['references'][reference]['fileNameRaw'])\n",
    "                    dst_path = join(newpath, self.yaml['test']['id'] + '_' + str(reference) + '_REF.csv')\n",
    "                    \n",
    "                    # Time Name\n",
    "                    timeName = self.yaml['test']['devices']['references'][reference]['index']['name']\n",
    "                    \n",
    "                    # Load Dataframe\n",
    "                    df = pd.read_csv(src_path, verbose=False, skiprows=[1]).set_index(timeName)\n",
    "                    df.index = pd.to_datetime(df.index)\n",
    "                    df.sort_index(inplace=True)\n",
    "                    df = df.groupby(pd.TimeGrouper(freq = self.yaml['test']['devices']['references'][reference]['index']['frequency'])).aggregate(np.mean)\n",
    "                    \n",
    "                    # Remove Duplicates and drop unnamed columns\n",
    "                    df = df[~df.index.duplicated(keep='first')]\n",
    "                    df.drop([i for i in df.columns if 'Unnamed' in i], axis=1, inplace=True)\n",
    "                                \n",
    "                    # Remove na\n",
    "                    df = df.apply(pd.to_numeric,errors='coerce')            \n",
    "                    df.fillna(0)\n",
    "                    \n",
    "                    # Export to csv in destination path\n",
    "                    df.to_csv(dst_path, sep=\",\")\n",
    "                    \n",
    "            \n",
    "            # Process kits\n",
    "            if 'kits' in self.yaml['test']['devices']:\n",
    "                for kit in self.yaml['test']['devices']['kits']:\n",
    "                    print ('Processing device: {}'.format(kit))\n",
    "                    src_path = join(raw_src_path, self.yaml['test']['devices']['kits'][kit]['fileNameRaw'])\n",
    "                    dst_path = join(newpath, self.yaml['test']['id'] + '_' + self.yaml['test']['devices']['kits'][kit]['type'] + '_' + str(kit) + '.csv')\n",
    "                    \n",
    "                    # Read file csv\n",
    "                    if self.yaml['test']['devices']['kits'][kit]['type_file'] == 'csv_new':\n",
    "                        skiprows_pd = range(1, 4)\n",
    "                        index_name = 'TIME'\n",
    "                        df = pd.read_csv(src_path, verbose=False, skiprows=skiprows_pd, delimiter = ',', encoding = 'utf-8')\n",
    "\n",
    "                    elif self.yaml['test']['devices']['kits'][kit]['type_file'] == 'csv_old':\n",
    "                        index_name = 'Time'\n",
    "                        df = pd.read_csv(src_path, verbose=False, encoding = 'utf-8')\n",
    "                        \n",
    "                    elif self.yaml['test']['devices']['kits'][kit]['type_file'] == 'csv_ms':\n",
    "                        index_name = 'Time'\n",
    "                        df = pd.read_csv(src_path, verbose=False, encoding = 'utf-8', parse_dates=[[0,1]], date_parser=date_parser)\n",
    "                    \n",
    "                    # Find name in case of extra weird characters\n",
    "                    for column in df.columns:\n",
    "                        if index_name in column: index_found = column\n",
    "                            \n",
    "                    df.set_index(index_found, inplace = True)\n",
    "                    df.index = pd.to_datetime(df.index).tz_localize('UTC').tz_convert(self.yaml['test']['devices']['kits'][kit]['location'])\n",
    "                    df.sort_index(inplace=True)\n",
    "                            \n",
    "                    # Remove Duplicates and drop unnamed columns\n",
    "                    # df = df[~df.index.duplicated(keep='first')]\n",
    "                    df.drop([i for i in df.columns if 'Unnamed' in i], axis=1, inplace=True)\n",
    "                                \n",
    "                    # Remove na\n",
    "                    df = df.apply(pd.to_numeric, errors='coerce')            \n",
    "                    df.fillna(0)\n",
    "                        \n",
    "                    df.to_csv(dst_path, sep=\",\")\n",
    "                    \n",
    "                    ## Import units and ids\n",
    "                    dict_header = dict()\n",
    "                    with open(src_path, 'rb') as csvfile:\n",
    "                        readercsv = csv.reader(csvfile, delimiter = ',')\n",
    "                        line = 0\n",
    "                    \n",
    "                        header = next(readercsv)[1:]\n",
    "                        unit = next(readercsv)[1:]\n",
    "                        ids = next(readercsv)[1:]\n",
    "                    \n",
    "                        for key in header:\n",
    "                            dict_header[key] = dict()\n",
    "                            dict_header[key]['unit'] = unit[header.index(key)]\n",
    "                            dict_header[key]['id'] = ids[header.index(key)]\n",
    "                        \n",
    "                        self.yaml['test']['devices']['kits'][kit]['metadata'] = dict_header\n",
    "                    \n",
    "                    ## Load txt info\n",
    "                    if self.yaml['test']['devices']['kits'][kit]['fileNameInfo'] != '':\n",
    "                        src_path_info = join(raw_src_path, self.yaml['test']['devices']['kits'][kit]['fileNameInfo'])\n",
    "                        dict_info = dict()\n",
    "                        with open(src_path_info, 'rb') as infofile:\n",
    "                            for line in infofile:\n",
    "                                line = line.strip('\\r\\n')\n",
    "                                splitter = line.find(':')\n",
    "                                dict_info[line[:splitter]]= line[splitter+2:] # Accounting for the space\n",
    "                           \n",
    "                        self.yaml['test']['devices']['kits'][kit]['info'] = dict_info\n",
    "                \n",
    "            \n",
    "            # Create yaml with test description\n",
    "            with open(join(newpath, 'test_description.yaml'), 'w') as yaml_file:\n",
    "                yaml.dump(self.yaml, yaml_file)\n",
    "                \n",
    "            print ('Test Creation Finished')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add details OK\n",
      "Add device OK\n",
      "Add device files OK\n",
      "Add device OK\n",
      "Add device files OK\n",
      "Processing device: SCS21002\n",
      "Processing device: SCS21001\n",
      "Test Creation Finished\n"
     ]
    }
   ],
   "source": [
    "date = '2019-01-10'\n",
    "who = 'EXT'\n",
    "name = 'TBOO_CHECK'\n",
    "\n",
    "comment = '''\n",
    "**Comment:** \n",
    "CHECK TBoo Data since he cannot upload\n",
    "'''\n",
    "\n",
    "date = pd.to_datetime(date)\n",
    "\n",
    "test_id = date.strftime('%Y-%m') + '_' + who + '_' + name\n",
    "\n",
    "# Create test object\n",
    "test = test_object(test_id)\n",
    "\n",
    "# Add General test details\n",
    "test.add_details(project = 'iscape', \n",
    "                 commit = 'various', \n",
    "                 author = 'Tboo', \n",
    "                 type_test = 'outdoor', \n",
    "                 report = '', \n",
    "                 comment = comment)\n",
    "\n",
    "# Add Device (as many as needed)\n",
    "test.add_device('SCS21001', \n",
    "                device_type = 'KIT', \n",
    "                sck_version = '2.0', \n",
    "                pm_sensor = 'none', \n",
    "                location = 'Europe/Madrid')\n",
    "\n",
    "test.device_files('SCS21001', \n",
    "                  fileNameRaw = 'Log_Concat_SCS21001.csv', \n",
    "                  fileNameInfo = '', \n",
    "                  frequency = '',\n",
    "                  type_file = 'csv_new')\n",
    "\n",
    "# Add Device (as many as needed)\n",
    "test.add_device('SCS21002', \n",
    "                device_type = 'KIT', \n",
    "                sck_version = '2.0', \n",
    "                pm_sensor = 'none', \n",
    "                location = 'Europe/Madrid')\n",
    "\n",
    "test.device_files('SCS21002', \n",
    "                  fileNameRaw = 'Log_Concat_SCS21002.csv', \n",
    "                  fileNameInfo = '', \n",
    "                  frequency = '',\n",
    "                  type_file = 'csv_new')\n",
    "\n",
    "\n",
    "# Add References (as many as needed) if none, just comment it\n",
    "# test.add_reference('ARPAE', \n",
    "#                   fileNameRaw = 'ARPAE.csv', \n",
    "#                   index = {'name' : 'Time',\n",
    "#                            'format' : '%Y-%m-%dT%H%M%S',\n",
    "#                            'frequency' : '1Min'}, \n",
    "#                   channels = {'pollutants' : ('CO', 'O3', 'NO2', 'NO', 'NOX'), \n",
    "#                               'units' : ('mg/m3', 'ug/m3', 'ug/m3', 'ug/m3', 'ug/m3'),\n",
    "#                               'names' : ('CO mg/m3', 'O3 ug/m3', 'NO2 ug/m3', 'NO ug/m3', 'NOX ug/m3')\n",
    "#                              })\n",
    "\n",
    "\n",
    "# Create folder structure under data subdir\n",
    "newpath = join(rootDirectory, 'data', date.strftime('%Y'), date.strftime('%m'), test_id)\n",
    "\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "# Process the stuff\n",
    "test.process_files(rootDirectory, newpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Test (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_name = '2018-10_INT_TEST_TEMP_PM_CHARGE_SD'\n",
    "test_year = test_name[0:4]\n",
    "test_month = test_name[5:7]\n",
    "newpath = join(rootDirectory, 'data', test_year, test_month, test_name)\n",
    "print newpath\n",
    "\n",
    "with open(join(newpath, 'test_description.yaml'), 'r') as yaml_file:\n",
    "    yaml1 = yaml.load(yaml_file)\n",
    "    \n",
    "display(yaml1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "178px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
