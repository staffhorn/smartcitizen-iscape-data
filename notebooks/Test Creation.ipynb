{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     127
    ]
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.genUID = function() {\n",
       "    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {\n",
       "        var r = Math.random()*16|0, v = c == 'x' ? r : (r&0x3|0x8);\n",
       "        return v.toString(16);\n",
       "    });\n",
       "};\n",
       "\n",
       "\n",
       "define('graphWidget', [\"@jupyter-widgets/base\"], function (widget) {\n",
       "\n",
       "    var GraphView = widget.DOMWidgetView.extend({\n",
       "        render: function(){\n",
       "            var that = this;\n",
       "\n",
       "            var graphId = window.genUID();\n",
       "            var loadingId = 'loading-'+graphId;\n",
       "\n",
       "\n",
       "            var _graph_url = that.model.get('_graph_url');\n",
       "\n",
       "            // variable plotlyDomain in the case of enterprise\n",
       "            var url_parts = _graph_url.split('/');\n",
       "            var plotlyDomain = url_parts[0] + '//' + url_parts[2];\n",
       "\n",
       "            if(!('plotlyDomains' in window)){\n",
       "                window.plotlyDomains = {};\n",
       "            }\n",
       "            window.plotlyDomains[graphId] = plotlyDomain;\n",
       "\n",
       "            // Place IFrame in output cell div `$el`\n",
       "            that.$el.css('width', '100%');\n",
       "            that.$graph = $(['<iframe id=\"'+graphId+'\"',\n",
       "                             'src=\"'+_graph_url+'.embed\"',\n",
       "                             'seamless',\n",
       "                             'style=\"border: none;\"',\n",
       "                             'width=\"100%\"',\n",
       "                             'height=\"600\">',\n",
       "                             '</iframe>'].join(' '));\n",
       "            that.$graph.appendTo(that.$el);\n",
       "\n",
       "            that.$loading = $('<div id=\"'+loadingId+'\">Initializing...</div>')\n",
       "                            .appendTo(that.$el);\n",
       "\n",
       "            // for some reason the 'width' is being changed in IPython 3.0.0\n",
       "            // for the containing `div` element. There's a flicker here, but\n",
       "            // I was unable to fix it otherwise.\n",
       "            setTimeout(function ()  {\n",
       "                if (IPYTHON_VERSION === '3') {\n",
       "                    $('#' + graphId)[0].parentElement.style.width = '100%';\n",
       "                }\n",
       "            }, 500);\n",
       "\n",
       "            // initialize communication with the iframe\n",
       "            if(!('pingers' in window)){\n",
       "                window.pingers = {};\n",
       "            }\n",
       "\n",
       "            window.pingers[graphId] = setInterval(function() {\n",
       "                that.graphContentWindow = $('#'+graphId)[0].contentWindow;\n",
       "                that.graphContentWindow.postMessage({task: 'ping'}, plotlyDomain);\n",
       "            }, 200);\n",
       "\n",
       "            // Assign a message listener to the 'message' events\n",
       "            // from iframe's postMessage protocol.\n",
       "            // Filter the messages by iframe src so that the right message\n",
       "            // gets passed to the right widget\n",
       "            if(!('messageListeners' in window)){\n",
       "                 window.messageListeners = {};\n",
       "            }\n",
       "\n",
       "            window.messageListeners[graphId] = function(e) {\n",
       "                if(_graph_url.indexOf(e.origin)>-1) {\n",
       "                    var frame = document.getElementById(graphId);\n",
       "\n",
       "                    if(frame === null){\n",
       "                        // frame doesn't exist in the dom anymore, clean up it's old event listener\n",
       "                        window.removeEventListener('message', window.messageListeners[graphId]);\n",
       "                        clearInterval(window.pingers[graphId]);\n",
       "                    } else if(frame.contentWindow === e.source) {\n",
       "                        // TODO: Stop event propagation, so each frame doesn't listen and filter\n",
       "                        var frameContentWindow = $('#'+graphId)[0].contentWindow;\n",
       "                        var message = e.data;\n",
       "\n",
       "                        if('pong' in message && message.pong) {\n",
       "                            $('#loading-'+graphId).hide();\n",
       "                            clearInterval(window.pingers[graphId]);\n",
       "                            that.send({event: 'pong', graphId: graphId});\n",
       "                        } else if (message.type==='hover' ||\n",
       "                                   message.type==='zoom'  ||\n",
       "                                   message.type==='click' ||\n",
       "                                   message.type==='unhover') {\n",
       "\n",
       "                            // click and hover events contain all of the data in the traces,\n",
       "                            // which can be a very large object and may take a ton of time\n",
       "                            // to pass to the python backend. Strip out the data, and require\n",
       "                            // the user to call get_figure if they need trace information\n",
       "                            if(message.type !== 'zoom') {\n",
       "                                for(var i in message.points) {\n",
       "                                    delete message.points[i].data;\n",
       "                                    delete message.points[i].fullData;\n",
       "                                }\n",
       "                            }\n",
       "                            that.send({event: message.type, message: message, graphId: graphId});\n",
       "                        } else if (message.task === 'getAttributes') {\n",
       "                            that.send({event: 'getAttributes', response: message.response});\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            };\n",
       "\n",
       "            window.removeEventListener('message', window.messageListeners[graphId]);\n",
       "            window.addEventListener('message', window.messageListeners[graphId]);\n",
       "\n",
       "        },\n",
       "\n",
       "        update: function() {\n",
       "            // Listen for messages from the graph widget in python\n",
       "            var jmessage = this.model.get('_message');\n",
       "            var message = JSON.parse(jmessage);\n",
       "\n",
       "            // check for duplicate messages\n",
       "            if(!('messageIds' in window)){\n",
       "                window.messageIds = {};\n",
       "            }\n",
       "\n",
       "            if(!(message.uid in window.messageIds)){\n",
       "                // message hasn't been received yet, do stuff\n",
       "                window.messageIds[message.uid] = true;\n",
       "\n",
       "                if (message.fadeTo) {\n",
       "                    this.fadeTo(message);\n",
       "                } else {\n",
       "                    var plot = $('#' + message.graphId)[0].contentWindow;\n",
       "                    plot.postMessage(message, window.plotlyDomains[message.graphId]);\n",
       "                }\n",
       "            }\n",
       "\n",
       "            return GraphView.__super__.update.apply(this);\n",
       "        },\n",
       "\n",
       "        /**\n",
       "         * Wrapper for jquery's `fadeTo` function.\n",
       "         *\n",
       "         * @param message Contains the id we need to find the element.\n",
       "         */\n",
       "        fadeTo: function (message) {\n",
       "            var plot = $('#' + message.graphId);\n",
       "            plot.fadeTo(message.duration, message.opacity);\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Register the GraphView with the widget manager.\n",
       "    return {\n",
       "        GraphView: GraphView\n",
       "    }\n",
       "\n",
       "});\n",
       "\n",
       "//@ sourceURL=graphWidget.js\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "import io, pytz, os, time, datetime\n",
    "from os.path import dirname, join, abspath\n",
    "from os import getcwd, pardir\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import markdown\n",
    "from dateutil import parser\n",
    "\n",
    "from IPython.display import display, Markdown, FileLink, FileLinks, clear_output, HTML\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display, clear_output\n",
    "from plotly.widgets import GraphWidget\n",
    "    \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import csv\n",
    "\n",
    "## Get Root Directory\n",
    "rootDirectory = abspath(abspath(join(getcwd(), pardir)))\n",
    "\n",
    "yaml1 = {}\n",
    "\n",
    "class test_object:\n",
    "    \n",
    "    def __init__(self, ID):\n",
    "        self.ID = ID\n",
    "        self.yaml = {}\n",
    "        self.yaml['test'] = dict()\n",
    "        self.yaml['test']['id'] = ID\n",
    "        self.yaml['test']['devices'] = dict()\n",
    "        self.yaml['test']['devices']['kits'] = dict()       \n",
    "    \n",
    "    def add_details(self, project = 'smartcitizen', commit = '', author = '', type_test = '', report = '', comment = ''):\n",
    "        try:\n",
    "            self.yaml['test']['project'] = project\n",
    "            self.yaml['test']['commit'] = commit\n",
    "            self.yaml['test']['author'] = author\n",
    "            self.yaml['test']['type_test'] = type_test\n",
    "            self.yaml['test']['report'] = report\n",
    "            self.yaml['test']['comment'] = markdown.markdown(comment)\n",
    "            print 'Add details OK'\n",
    "        except:\n",
    "            print 'Add device NOK'\n",
    "            pass\n",
    "\n",
    "    def add_device(self, device, device_type = 'KIT', sck_version = '2.0', pm_sensor = '', alphasense = {}, location = 'Europe/Madrid'):\n",
    "        try:\n",
    "            self.yaml['test']['devices']['kits'][device] = dict()\n",
    "            self.yaml['test']['devices']['kits'][device]['type'] = device_type\n",
    "            self.yaml['test']['devices']['kits'][device]['SCK'] = sck_version\n",
    "            self.yaml['test']['devices']['kits'][device]['PM'] = pm_sensor\n",
    "            self.yaml['test']['devices']['kits'][device]['location'] = location\n",
    "            #### Alphasense\n",
    "            if alphasense != {}:\n",
    "                self.yaml['test']['devices']['kits'][device]['alphasense'] = alphasense\n",
    "                \n",
    "            print 'Add device OK'\n",
    "        except:\n",
    "            print 'Add device NOK'\n",
    "            pass\n",
    "\n",
    "    def device_files(self, device, fileNameRaw = '', fileNameInfo = '', frequency = '1Min', type_file = 'csv_new'):\n",
    "        try:\n",
    "            self.yaml['test']['devices']['kits'][device]['fileNameRaw'] = fileNameRaw\n",
    "            self.yaml['test']['devices']['kits'][device]['fileNameInfo'] = fileNameInfo\n",
    "            fileNameProc = (self.yaml['test']['id'] + '_' + self.yaml['test']['devices']['kits'][device]['type'] + '_' + str(device) + '.csv')\n",
    "            self.yaml['test']['devices']['kits'][device]['fileNameProc'] = fileNameProc\n",
    "            self.yaml['test']['devices']['kits'][device]['frequency'] = frequency\n",
    "            self.yaml['test']['devices']['kits'][device]['type_file'] = type_file  \n",
    "            print 'Add device files OK'\n",
    "        \n",
    "        except:\n",
    "            print 'Add device files NOK'\n",
    "            pass\n",
    "    \n",
    "    def add_reference(self, reference, fileNameRaw = '', index = {}, channels = {}, location = ''):\n",
    "        if 'reference' not in self.yaml['test']['devices']:\n",
    "            self.yaml['test']['devices']['reference'] = dict()\n",
    "        \n",
    "        self.yaml['test']['devices']['references'][reference] = dict()\n",
    "        self.yaml['test']['devices']['references'][reference]['fileNameRaw'] = fileNameRaw\n",
    "        self.yaml['test']['devices']['references'][reference]['index'] = index\n",
    "        self.yaml['test']['devices']['references'][reference]['channels'] = channels\n",
    "    \n",
    "    def process_files(self, _rootDirectory, _newpath):\n",
    "        \n",
    "        def get_raw_files():\n",
    "                list_raw_files = []\n",
    "                \n",
    "                if 'kits' in self.yaml['test']['devices']:\n",
    "                    for kit in self.yaml['test']['devices']['kits']:\n",
    "                        list_raw_files.append(self.yaml['test']['devices']['kits'][kit]['fileNameRaw'])\n",
    "                        \n",
    "                if 'references' in self.yaml['test']['devices']:\n",
    "                    for reference in self.yaml['test']['devices']['references']:\n",
    "                        list_raw_files.append(self.yaml['test']['devices']['references'][reference]['fileNameRaw'])\n",
    "                        \n",
    "                return list_raw_files    \n",
    "        \n",
    "        def copy_raw_files(_raw_src_path, _raw_dst_path, _list_raw_files):\n",
    "            \n",
    "                try: \n",
    "\n",
    "                    for item in _list_raw_files:\n",
    "                        s = join(_raw_src_path, item)\n",
    "                        d = join(_raw_dst_path, item)\n",
    "                        copyfile(s, d)\n",
    "                    \n",
    "                    return True\n",
    "                \n",
    "                except:\n",
    "\n",
    "                    return False\n",
    "                \n",
    "        def date_parser(s, a):\n",
    "            return parser.parse(s).replace(microsecond=int(a[-3:])*1000)\n",
    "    \n",
    "        # Define Paths\n",
    "        raw_src_path = join(_rootDirectory, 'data', 'RAW_DATA')\n",
    "        raw_dst_path = join(_newpath, 'RAW_DATA')    \n",
    "        \n",
    "        # Create Paths\n",
    "        if not os.path.exists(raw_dst_path):\n",
    "            os.makedirs(raw_dst_path)\n",
    "        \n",
    "        list_raw_files = get_raw_files()\n",
    "        # Copy raw files and process data\n",
    "        if copy_raw_files(raw_src_path, raw_dst_path, list_raw_files):\n",
    "            # Process references\n",
    "            if 'references' in self.yaml['test']['devices']:\n",
    "                for reference in self.yaml['test']['devices']['references']:\n",
    "                    src_path = join(raw_src_path, self.yaml['test']['devices']['references'][reference]['fileNameRaw'])\n",
    "                    dst_path = join(newpath, self.yaml['test']['id'] + '_' + str(reference) + '_REF.csv')\n",
    "                    \n",
    "                    # Time Name\n",
    "                    timeName = self.yaml['test']['devices']['references'][reference]['index']['name']\n",
    "                    \n",
    "                    # Load Dataframe\n",
    "                    df = pd.read_csv(src_path, verbose=False, skiprows=[1]).set_index(timeName)\n",
    "                    df.index = pd.to_datetime(df.index)\n",
    "                    df.sort_index(inplace=True)\n",
    "                    df = df.groupby(pd.TimeGrouper(freq = self.yaml['test']['devices']['references'][reference]['index']['frequency'])).aggregate(np.mean)\n",
    "                    \n",
    "                    # Remove Duplicates and drop unnamed columns\n",
    "                    df = df[~df.index.duplicated(keep='first')]\n",
    "                    df.drop([i for i in df.columns if 'Unnamed' in i], axis=1, inplace=True)\n",
    "                                \n",
    "                    # Remove na\n",
    "                    df = df.apply(pd.to_numeric,errors='coerce')            \n",
    "                    df.fillna(0)\n",
    "                    \n",
    "                    # Export to csv in destination path\n",
    "                    df.to_csv(dst_path, sep=\",\")\n",
    "                    \n",
    "            \n",
    "            # Process kits\n",
    "            if 'kits' in self.yaml['test']['devices']:\n",
    "                for kit in self.yaml['test']['devices']['kits']:\n",
    "                    print ('Processing device: {}'.format(kit))\n",
    "                    src_path = join(raw_src_path, self.yaml['test']['devices']['kits'][kit]['fileNameRaw'])\n",
    "                    dst_path = join(newpath, self.yaml['test']['id'] + '_' + self.yaml['test']['devices']['kits'][kit]['type'] + '_' + str(kit) + '.csv')\n",
    "                    \n",
    "                    # Read file csv\n",
    "                    if self.yaml['test']['devices']['kits'][kit]['type_file'] == 'csv_new':\n",
    "                        skiprows_pd = range(1, 4)\n",
    "                        index_name = 'TIME'\n",
    "                        df = pd.read_csv(src_path, verbose=False, skiprows=skiprows_pd, delimiter = ',', encoding = 'utf-8')\n",
    "\n",
    "                    elif self.yaml['test']['devices']['kits'][kit]['type_file'] == 'csv_old':\n",
    "                        index_name = 'Time'\n",
    "                        df = pd.read_csv(src_path, verbose=False, encoding = 'utf-8')\n",
    "                        \n",
    "                    elif self.yaml['test']['devices']['kits'][kit]['type_file'] == 'csv_ms':\n",
    "                        index_name = 'Time'\n",
    "                        df = pd.read_csv(src_path, verbose=False, encoding = 'utf-8', parse_dates=[[0,1]], date_parser=date_parser)\n",
    "                    \n",
    "                    # Find name in case of extra weird characters\n",
    "                    for column in df.columns:\n",
    "                        if index_name in column: index_found = column\n",
    "                            \n",
    "                    df.set_index(index_found, inplace = True)\n",
    "                    df.index = pd.to_datetime(df.index).tz_localize('UTC').tz_convert(self.yaml['test']['devices']['kits'][kit]['location'])\n",
    "                    df.sort_index(inplace=True)\n",
    "                            \n",
    "                    # Remove Duplicates and drop unnamed columns\n",
    "                    # df = df[~df.index.duplicated(keep='first')]\n",
    "                    df.drop([i for i in df.columns if 'Unnamed' in i], axis=1, inplace=True)\n",
    "                                \n",
    "                    # Remove na\n",
    "                    df = df.apply(pd.to_numeric, errors='coerce')            \n",
    "                    df.fillna(0)\n",
    "                        \n",
    "                    df.to_csv(dst_path, sep=\",\")\n",
    "                    \n",
    "                    ## Import units and ids\n",
    "                    dict_header = dict()\n",
    "                    with open(src_path, 'rb') as csvfile:\n",
    "                        readercsv = csv.reader(csvfile, delimiter = ',')\n",
    "                        line = 0\n",
    "                    \n",
    "                        header = next(readercsv)[1:]\n",
    "                        unit = next(readercsv)[1:]\n",
    "                        ids = next(readercsv)[1:]\n",
    "                    \n",
    "                        for key in header:\n",
    "                            dict_header[key] = dict()\n",
    "                            dict_header[key]['unit'] = unit[header.index(key)]\n",
    "                            dict_header[key]['id'] = ids[header.index(key)]\n",
    "                        \n",
    "                        self.yaml['test']['devices']['kits'][kit]['metadata'] = dict_header\n",
    "                    \n",
    "                    ## Load txt info\n",
    "                    if self.yaml['test']['devices']['kits'][kit]['fileNameInfo'] != '':\n",
    "                        src_path_info = join(raw_src_path, self.yaml['test']['devices']['kits'][kit]['fileNameInfo'])\n",
    "                        dict_info = dict()\n",
    "                        with open(src_path_info, 'rb') as infofile:\n",
    "                            for line in infofile:\n",
    "                                line = line.strip('\\r\\n')\n",
    "                                splitter = line.find(':')\n",
    "                                dict_info[line[:splitter]]= line[splitter+2:] # Accounting for the space\n",
    "                           \n",
    "                        self.yaml['test']['devices']['kits'][kit]['info'] = dict_info\n",
    "                \n",
    "            \n",
    "            # Create yaml with test description\n",
    "            with open(join(newpath, 'test_description.yaml'), 'w') as yaml_file:\n",
    "                yaml.dump(self.yaml, yaml_file)\n",
    "                \n",
    "            print ('Test Creation Finished')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add details OK\n",
      "Add device OK\n",
      "Add device files OK\n",
      "Processing device: KIT\n",
      "Test Creation Finished\n"
     ]
    }
   ],
   "source": [
    "date = '2019-01-10'\n",
    "who = 'INT'\n",
    "name = 'CCS811'\n",
    "\n",
    "comment = '''\n",
    "**Comment:** \n",
    "CCS811\n",
    "'''\n",
    "\n",
    "date = pd.to_datetime(date)\n",
    "\n",
    "test_id = date.strftime('%Y-%m') + '_' + who + '_' + name\n",
    "\n",
    "# Create test object\n",
    "test = test_object(test_id)\n",
    "\n",
    "# Add General test details\n",
    "test.add_details(project = 'smartcitizen', \n",
    "                 commit = 'various', \n",
    "                 author = 'Oscar', \n",
    "                 type_test = 'indoor', \n",
    "                 report = '', \n",
    "                 comment = comment)\n",
    "\n",
    "# Add Device (as many as needed)\n",
    "test.add_device('KIT', \n",
    "                device_type = 'KIT', \n",
    "                sck_version = '2.0', \n",
    "                pm_sensor = 'none', \n",
    "                location = 'Europe/Madrid')\n",
    "\n",
    "test.device_files('KIT', \n",
    "                  fileNameRaw = 'Log_Concat.csv', \n",
    "                  fileNameInfo = '', \n",
    "                  frequency = '',\n",
    "                  type_file = 'csv_new')\n",
    "\n",
    "\n",
    "# Add References (as many as needed) if none, just comment it\n",
    "# test.add_reference('ARPAE', \n",
    "#                   fileNameRaw = 'ARPAE.csv', \n",
    "#                   index = {'name' : 'Time',\n",
    "#                            'format' : '%Y-%m-%dT%H%M%S',\n",
    "#                            'frequency' : '1Min'}, \n",
    "#                   channels = {'pollutants' : ('CO', 'O3', 'NO2', 'NO', 'NOX'), \n",
    "#                               'units' : ('mg/m3', 'ug/m3', 'ug/m3', 'ug/m3', 'ug/m3'),\n",
    "#                               'names' : ('CO mg/m3', 'O3 ug/m3', 'NO2 ug/m3', 'NO ug/m3', 'NOX ug/m3')\n",
    "#                              })\n",
    "\n",
    "\n",
    "# Create folder structure under data subdir\n",
    "newpath = join(rootDirectory, 'data', date.strftime('%Y'), date.strftime('%m'), test_id)\n",
    "\n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "# Process the stuff\n",
    "test.process_files(rootDirectory, newpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Test (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_name = '2018-10_INT_TEST_TEMP_PM_CHARGE_SD'\n",
    "test_year = test_name[0:4]\n",
    "test_month = test_name[5:7]\n",
    "newpath = join(rootDirectory, 'data', test_year, test_month, test_name)\n",
    "print newpath\n",
    "\n",
    "with open(join(newpath, 'test_description.yaml'), 'r') as yaml_file:\n",
    "    yaml1 = yaml.load(yaml_file)\n",
    "    \n",
    "display(yaml1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "178px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
